{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "from IPython.display import Image\n",
    "init_notebook_mode(connected=True)\n",
    "%matplotlib inline\n",
    "\n",
    "import surprise\n",
    "from surprise import KNNBasic\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import Reader\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import KNNWithMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df = pd.read_csv('ratings_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1,5))\n",
    "data = Dataset.load_from_df(rating_df[['userId', 'movieId', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = []\n",
    "\n",
    "for i in [SVD(biased=False), KNNBasic(sim_options = {'user_based': True }), KNNBasic(sim_options = {'user_based': False})]:\n",
    "    results = cross_validate(i, data, measures=['MAE', 'RMSE'], cv = 5, verbose=True)\n",
    "\n",
    "    item = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    item = item.append(pd.Series([str(i).split(' ')[0].split('.')[-1]], index=['i']))\n",
    "\n",
    "    collector.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = pd.DataFrame(collector)\n",
    "\n",
    "new_algorithms = ['PMF','UserCF','ItemCF']\n",
    "collector['i'] = new_algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector2 = []\n",
    "\n",
    "for i in [KNNBasic(sim_options = {'name':'cosine','user_based': True}), KNNBasic(sim_options = {'name':'MSD', 'user_based':True }),\n",
    "                 KNNBasic(sim_options = {'name':'pearson','user_based': True}),\n",
    "                 KNNBasic(sim_options = {'name':'cosine', 'user_based':False }),KNNBasic(sim_options = {'name':'MSD', 'user_based':False }),\n",
    "                 KNNBasic(sim_options = {'name':'pearson','user_based': False}) \n",
    "                 ]:\n",
    "    \n",
    "    results = cross_validate(i, data, measures=['RMSE', 'MAE'], cv=5, verbose=False)\n",
    "    \n",
    "    item = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    item = item.append(pd.Series([str(i).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    \n",
    "    collector.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_algorithms2 = ['Cosine-UserCF','MSD-UserCF','Pearson-UserCF','Cosine-ItemCF','MSD-ItemCF','Pearson-ItemCF']\n",
    "collector2['i'] = new_algorithms2\n",
    "\n",
    "results2 = collector2.set_index('i').sort_values('test_rmse', ascending=False)\n",
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = results2[['test_rmse', 'test_mae']]\n",
    "matrix = data.values\n",
    "\n",
    "horizontal = [label.split('_')[1].upper() for label in data.columns.tolist()]\n",
    "vertical = data.index.tolist()\n",
    "\n",
    "h_label = 'Function'\n",
    "v_label = 'Algorithm'\n",
    "\n",
    "\n",
    "hovertexts = []\n",
    "annotations = []\n",
    "\n",
    "for i, y_value in enumerate(vertical):\n",
    "    row = []\n",
    "    for j, x_value in enumerate(horizontal):\n",
    "        annotation = matrix[i, j]\n",
    "        row.append('Error: {:.4f}<br>{}: {}<br>{}: {}<br>Fit Time: {:.3f}s<br>Test Time: {:.3f}s'.format(annotation, v_label, y_value ,h_label, x_value, \n",
    "                                                                                                         results2.loc[y_value]['fit_time'], \n",
    "                                                                                                         results2.loc[y_value]['test_time']))\n",
    "        annotations.append(dict(x=x_value, y=y_value, text='{:.4f}'.format(annotation), ax=0, ay=0, font=dict(color='#000000')))\n",
    "    hovertexts.append(row)\n",
    "\n",
    "trace = go.Heatmap(x = horizontal,\n",
    "                   y = vertical,\n",
    "                   z = data.values,\n",
    "                   text = hovertexts,\n",
    "                   hoverinfo = 'text',\n",
    "                   colorscale = 'Picnic',\n",
    "                   colorbar = dict(title = 'Error'))\n",
    "\n",
    "layout = go.Layout(title = 'Cross-validated Comparison of Algorithms',\n",
    "                   xaxis = dict(title = h_label),\n",
    "                   yaxis = dict(title = v_label,\n",
    "                                tickangle = -40),\n",
    "                   annotations = annotations)\n",
    "\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "img_bytes = fig.to_image(format = \"png\", width=600, height=450, scale=2)\n",
    "Image(img_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(rating_df[['userId', 'movieId', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "collector_ucf = []\n",
    "\n",
    "for i in range(1,30):\n",
    "    algorithm =KNNBasic(k=i, sim_options = {'name':'MSD','user_based': True})\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE', 'MAE'], cv=3, verbose=False)\n",
    "    \n",
    "    init_notebook_mode = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "       \n",
    "    collector_ucf.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector_icf = []\n",
    "\n",
    "for i in range(1,30):\n",
    "    algorithm = KNNBasic(k=i, sim_options = {'name':'MSD','user_based': False})\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE','MAE'], cv=3, verbose=False)\n",
    "    \n",
    "    item = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "        \n",
    "    collector_icf.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_ucf = pd.DataFrame(collector_ucf)\n",
    "benchmark_icf = pd.DataFrame(collector_icf)\n",
    "\n",
    "acc_userCF1 = benchmark_ucf['test_rmse']\n",
    "acc_itemCF1 = benchmark_icf['test_rmse']\n",
    "\n",
    "acc_userCF2 = benchmark_ucf['test_mae']\n",
    "acc_itemCF2 = benchmark_icf['test_mae']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_itemCF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_userCF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(range(1,30), acc_userCF1, label = \"User-based CF\")\n",
    "plt.plot(range(1,30), acc_itemCF1, label = \"Item-based CF\")\n",
    "plt.title('')\n",
    "plt.xlabel('Number of neighbors (K)', fontsize=12)\n",
    "plt.ylabel('RMSE', fontsize=12)\n",
    "\n",
    "plt.title('K Neighbors vs. RMSE (User-based CF and Item-based CF)', fontsize=18, y=1.03)\n",
    "plt.legend(loc='best')\n",
    "plt.grid(ls='dotted')\n",
    "\n",
    "plt.savefig(\"plot_f (RMSE).png\", dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(range(1,30), acc_userCF2, label = \"User-based CF\")\n",
    "plt.plot(range(1,30), acc_itemCF2, label = \"Item-based CF\")\n",
    "plt.title('')\n",
    "plt.xlabel('Number of neighbors (K)', fontsize=12)\n",
    "plt.ylabel('RMSE', fontsize=12)\n",
    "\n",
    "plt.title('K Neighbors vs. MAE (User-based CF and Item-based CF)', fontsize=18, y=1.03)\n",
    "plt.legend(loc='best')\n",
    "plt.grid(ls='dotted')\n",
    "\n",
    "plt.savefig(\"plot_f (MAE).png\", dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc_userCF1.idxmin()+1, \"RMSE:\", min(acc_userCF1))\n",
    "print(acc_itemCF1.idxmin()+1 , \"RMSE:\", min(acc_itemCF1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc_userCF2.idxmin()+1, \"MAE:\", min(acc_userCF2))\n",
    "print(acc_itemCF2.idxmin()+1 , \"MAE:\", min(acc_itemCF2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
